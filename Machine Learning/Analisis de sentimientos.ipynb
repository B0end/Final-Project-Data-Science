{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos pandas para leer la data en df\n",
    "import pandas as pd\n",
    "#con pandas_gbq es para interactuar con bigquery\n",
    "import pandas_gbq\n",
    "\n",
    "# Objetivo: Vamos a crear la conexión con BigQuery y vamos a leer mediante\n",
    "# consulta SQL desde Python.\n",
    "# Generamos conexion a bigquery\n",
    "\n",
    "from google.oauth2 import service_account # para generar conexion\n",
    "bq_cred = service_account.Credentials.from_service_account_file('cedar-pottery-388916-edca8400ae77.json')      \n",
    "query = \"\"\"\n",
    "    SELECT b.id, b.name, b.state, b.category, r.text, r.date\n",
    "    FROM `cedar-pottery-388916.conjunto_testing.beauty_business` AS b\n",
    "    JOIN `cedar-pottery-388916.conjunto_testing.business_beauty_reviews` AS r\n",
    "    ON b.id = r.business_id\n",
    "    LIMIT 1905190\n",
    "\"\"\"\n",
    "\n",
    "#Dialect standard: para usar BigQuery’s standard SQL dialect\n",
    "Analisis_Sentimientos = pd.read_gbq(query, project_id='cedar-pottery-388916', credentials =\n",
    "bq_cred, dialect='standard')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analisis_Sentimientos = Analisis_Sentimientos.dropna(subset=['text','category','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analisis_Sentimientos.drop(columns=\"id\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'Analisis_Sentimientos' is your DataFrame\n",
    "\n",
    "# Rename the 'date' column to 'year'\n",
    "Analisis_Sentimientos.rename(columns={'date': 'year'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def get_sentiment(text):\n",
    "    try:\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        sentiment_scores = analyzer.polarity_scores(text)\n",
    "        compound_score = sentiment_scores['compound']\n",
    "        \n",
    "        if compound_score > 0:\n",
    "            return 'Positivo'\n",
    "        elif compound_score < 0:\n",
    "            return 'Negativo'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "    except:\n",
    "        return 'Error'\n",
    "\n",
    "# Aplicar el análisis de sentimiento a la columna 'text' y crear la nueva columna 'sentiment'\n",
    "Analisis_Sentimientos['Sentimiento'] = Analisis_Sentimientos['text'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analisis_Sentimientos.to_csv('Analisis_Sentimientos.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
